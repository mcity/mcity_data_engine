{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import fiftyone as fo\n",
    "\n",
    "from fiftyone.utils.huggingface import load_from_hub\n",
    "from utils.data_loader import (\n",
    "    FiftyOneTorchDatasetCOCO,\n",
    "    FiftyOneTorchDatasetCOCOFilepaths,\n",
    "    TorchToHFDatasetCOCO,\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading config file fiftyone.yml from dbogdollumich/mcity_fisheye_v51\n",
      "Loading dataset\n",
      "<bound method Dataset.stats of Name:        dbogdollumich/mcity_fisheye_v51\n",
      "Media type:  image\n",
      "Num samples: 2744\n",
      "Persistent:  False\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:               fiftyone.core.fields.ObjectIdField\n",
      "    filepath:         fiftyone.core.fields.StringField\n",
      "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:       fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
      "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    location:         fiftyone.core.fields.StringField\n",
      "    name:             fiftyone.core.fields.StringField\n",
      "    timestamp:        fiftyone.core.fields.DateTimeField>\n",
      "<bound method Dataset.summary of Name:        dbogdollumich/mcity_fisheye_v51\n",
      "Media type:  image\n",
      "Num samples: 2744\n",
      "Persistent:  False\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:               fiftyone.core.fields.ObjectIdField\n",
      "    filepath:         fiftyone.core.fields.StringField\n",
      "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:       fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
      "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    location:         fiftyone.core.fields.StringField\n",
      "    name:             fiftyone.core.fields.StringField\n",
      "    timestamp:        fiftyone.core.fields.DateTimeField>\n",
      "dbogdollumich/mcity_fisheye_v51\n",
      "2744\n"
     ]
    }
   ],
   "source": [
    "tokens = {}\n",
    "with open(\"/home/dbogdoll/mcity_data_engine/.secret\", \"r\") as file:\n",
    "    for line in file:\n",
    "        key, value = line.strip().split(\"=\")\n",
    "        tokens[key] = value\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = tokens[\"HF_TOKEN\"]\n",
    "\n",
    "try:\n",
    "    dataset_v51 = load_from_hub(\"dbogdollumich/mcity_fisheye_v51\")\n",
    "except:\n",
    "    dataset_v51 = fo.load_dataset(\"dbogdollumich/mcity_fisheye_v51\")\n",
    "\n",
    "print(dataset_v51.stats)\n",
    "print(dataset_v51.summary)\n",
    "print(dataset_v51.name)\n",
    "print(len(dataset_v51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sample: {\n",
      "    'id': '670d7c398fccaa34bc6b2bbe',\n",
      "    'media_type': 'image',\n",
      "    'filepath': '/home/dbogdoll/fiftyone/huggingface/hub/dbogdollumich/mcity_fisheye_v51/data/Huron_Plymouth-Geddes_Huron_gs_Geddes_Huron1__2023-03-28__11__0_gs_Geddes_Huron1__2023-03-28__11__0__2023-03-28_11-06-01-107336.jpg',\n",
      "    'tags': ['train'],\n",
      "    'metadata': <ImageMetadata: {\n",
      "        'size_bytes': 263379,\n",
      "        'mime_type': 'image/jpeg',\n",
      "        'width': 1280,\n",
      "        'height': 960,\n",
      "        'num_channels': 3,\n",
      "    }>,\n",
      "    'created_at': datetime.datetime(2024, 10, 31, 21, 55, 4, 181000),\n",
      "    'last_modified_at': datetime.datetime(2024, 10, 31, 21, 55, 4, 181000),\n",
      "    'ground_truth': <Detections: {\n",
      "        'detections': [\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bac',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [0.24241120000000002, 0.52306885, 0.0265376, 0.0737743],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bad',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [0.2269187, 0.7153157, 0.0129146, 0.0396066],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bae',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [0.3742449, 0.1582507, 0.0414842, 0.0266786],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2baf',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [0.65836125, 0.3269119, 0.0526355, 0.0642542],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bb0',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [\n",
      "                    0.7404686500000001,\n",
      "                    0.38555629999999996,\n",
      "                    0.0279207,\n",
      "                    0.0500654,\n",
      "                ],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bb1',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [0.7818727, 0.41576135, 0.0219206, 0.0412053],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bb2',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [0.81200357, 0.45161405, 0.00939286, 0.0299519],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bb3',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [0.63259915, 0.39244385000000004, 0.0769097, 0.0800063],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bb4',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [0.8019707, 0.48487405, 0.0136186, 0.0315959],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bb5',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'truck',\n",
      "                'bounding_box': [0.834736325, 0.50085225, 0.00847535, 0.0277175],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bb6',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [0.849062615, 0.51908345, 0.00552077, 0.0152151],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bb7',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [0.6933976, 0.29832145, 0.0381168, 0.0503071],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bb8',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [0.7660819999999999, 0.3572017, 0.020914, 0.0455506],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bb9',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [0.8003375, 0.39528825, 0.015629, 0.0362635],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bba',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [0.161003985, 0.528913, 0.00847403, 0.022264],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bbb',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'trailer',\n",
      "                'bounding_box': [0.14937178, 0.5162942500000001, 0.00983844, 0.0297595],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bbc',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'car',\n",
      "                'bounding_box': [0.8589028249999999, 0.51947415, 0.00343635, 0.0149697],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '670d7c398fccaa34bc6b2bbd',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'motorbike/cycler',\n",
      "                'bounding_box': [0.81997275, 0.35570065, 0.0078125, 0.0104167],\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "        ],\n",
      "    }>,\n",
      "    'location': 'Huron_Plymouth-Geddes',\n",
      "    'name': 'Huron_Plymouth-Geddes_Huron_gs_Geddes_Huron1',\n",
      "    'timestamp': datetime.datetime(2023, 3, 28, 11, 6, 1),\n",
      "}>\n",
      "<Detections: {\n",
      "    'detections': [\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bac',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [0.24241120000000002, 0.52306885, 0.0265376, 0.0737743],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bad',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [0.2269187, 0.7153157, 0.0129146, 0.0396066],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bae',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [0.3742449, 0.1582507, 0.0414842, 0.0266786],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2baf',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [0.65836125, 0.3269119, 0.0526355, 0.0642542],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bb0',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [\n",
      "                0.7404686500000001,\n",
      "                0.38555629999999996,\n",
      "                0.0279207,\n",
      "                0.0500654,\n",
      "            ],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bb1',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [0.7818727, 0.41576135, 0.0219206, 0.0412053],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bb2',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [0.81200357, 0.45161405, 0.00939286, 0.0299519],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bb3',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [0.63259915, 0.39244385000000004, 0.0769097, 0.0800063],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bb4',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [0.8019707, 0.48487405, 0.0136186, 0.0315959],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bb5',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'truck',\n",
      "            'bounding_box': [0.834736325, 0.50085225, 0.00847535, 0.0277175],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bb6',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [0.849062615, 0.51908345, 0.00552077, 0.0152151],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bb7',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [0.6933976, 0.29832145, 0.0381168, 0.0503071],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bb8',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [0.7660819999999999, 0.3572017, 0.020914, 0.0455506],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bb9',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [0.8003375, 0.39528825, 0.015629, 0.0362635],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bba',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [0.161003985, 0.528913, 0.00847403, 0.022264],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bbb',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'trailer',\n",
      "            'bounding_box': [0.14937178, 0.5162942500000001, 0.00983844, 0.0297595],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bbc',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'car',\n",
      "            'bounding_box': [0.8589028249999999, 0.51947415, 0.00343635, 0.0149697],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '670d7c398fccaa34bc6b2bbd',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'motorbike/cycler',\n",
      "            'bounding_box': [0.81997275, 0.35570065, 0.0078125, 0.0104167],\n",
      "            'mask': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "        }>,\n",
      "    ],\n",
      "}>\n",
      "18\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bac',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [0.24241120000000002, 0.52306885, 0.0265376, 0.0737743],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.24241120000000002, 0.52306885, 0.0265376, 0.0737743]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bad',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [0.2269187, 0.7153157, 0.0129146, 0.0396066],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.2269187, 0.7153157, 0.0129146, 0.0396066]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bae',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [0.3742449, 0.1582507, 0.0414842, 0.0266786],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.3742449, 0.1582507, 0.0414842, 0.0266786]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2baf',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [0.65836125, 0.3269119, 0.0526355, 0.0642542],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.65836125, 0.3269119, 0.0526355, 0.0642542]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bb0',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [\n",
      "        0.7404686500000001,\n",
      "        0.38555629999999996,\n",
      "        0.0279207,\n",
      "        0.0500654,\n",
      "    ],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.7404686500000001, 0.38555629999999996, 0.0279207, 0.0500654]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bb1',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [0.7818727, 0.41576135, 0.0219206, 0.0412053],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.7818727, 0.41576135, 0.0219206, 0.0412053]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bb2',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [0.81200357, 0.45161405, 0.00939286, 0.0299519],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.81200357, 0.45161405, 0.00939286, 0.0299519]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bb3',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [0.63259915, 0.39244385000000004, 0.0769097, 0.0800063],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.63259915, 0.39244385000000004, 0.0769097, 0.0800063]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bb4',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [0.8019707, 0.48487405, 0.0136186, 0.0315959],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.8019707, 0.48487405, 0.0136186, 0.0315959]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bb5',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'truck',\n",
      "    'bounding_box': [0.834736325, 0.50085225, 0.00847535, 0.0277175],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.834736325, 0.50085225, 0.00847535, 0.0277175]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bb6',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [0.849062615, 0.51908345, 0.00552077, 0.0152151],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.849062615, 0.51908345, 0.00552077, 0.0152151]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bb7',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [0.6933976, 0.29832145, 0.0381168, 0.0503071],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.6933976, 0.29832145, 0.0381168, 0.0503071]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bb8',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [0.7660819999999999, 0.3572017, 0.020914, 0.0455506],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.7660819999999999, 0.3572017, 0.020914, 0.0455506]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bb9',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [0.8003375, 0.39528825, 0.015629, 0.0362635],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.8003375, 0.39528825, 0.015629, 0.0362635]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bba',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [0.161003985, 0.528913, 0.00847403, 0.022264],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.161003985, 0.528913, 0.00847403, 0.022264]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bbb',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'trailer',\n",
      "    'bounding_box': [0.14937178, 0.5162942500000001, 0.00983844, 0.0297595],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.14937178, 0.5162942500000001, 0.00983844, 0.0297595]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bbc',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'car',\n",
      "    'bounding_box': [0.8589028249999999, 0.51947415, 0.00343635, 0.0149697],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.8589028249999999, 0.51947415, 0.00343635, 0.0149697]\n",
      "<Detection: {\n",
      "    'id': '670d7c398fccaa34bc6b2bbd',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'motorbike/cycler',\n",
      "    'bounding_box': [0.81997275, 0.35570065, 0.0078125, 0.0104167],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "}>\n",
      "[0.81997275, 0.35570065, 0.0078125, 0.0104167]\n"
     ]
    }
   ],
   "source": [
    "sample = dataset_v51.first()\n",
    "print(sample)\n",
    "sample2 = dataset_v51[sample.filepath]\n",
    "\n",
    "ground_truth = sample[\"ground_truth\"]\n",
    "print(ground_truth)\n",
    "print(len(ground_truth[\"detections\"]))\n",
    "\n",
    "for detection in ground_truth[\"detections\"]:\n",
    "    print(detection)\n",
    "    print(detection.bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "# dataset_v51 = dataset_v51.take(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Voxel51 dataset: 100%|██████████| 2744/2744 [00:02<00:00, 1089.91it/s]\n"
     ]
    }
   ],
   "source": [
    "torch_dataset_filepaths = FiftyOneTorchDatasetCOCOFilepaths(dataset_v51)\n",
    "torch_dataloader_filepaths = DataLoader(\n",
    "    torch_dataset_filepaths,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=32,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    prefetch_factor=2,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Voxel51 dataset: 100%|██████████| 2744/2744 [00:05<00:00, 515.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'truck', 'bus', 'trailer', 'motorbike/cycler', 'pedestrian', 'van', 'pickup']\n",
      "{'val', 'train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch_dataset_managed = FiftyOneTorchDatasetCOCO(dataset_v51)\n",
    "torch_dataloader_managed = DataLoader(\n",
    "    torch_dataset_managed,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=32,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    prefetch_factor=2,\n",
    "    collate_fn=lambda batch: list(zip(*batch)),\n",
    ")\n",
    "\n",
    "print(torch_dataset_managed.get_classes())\n",
    "print(torch_dataset_managed.get_splits())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1912271fb241849c92d5970ff5f896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a5a27e1e3c4376becaf7abd06a6198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "converter = TorchToHFDatasetCOCO(torch_dataset_managed)\n",
    "hf_dataset = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.utils.coco as fouc\n",
    "import torch\n",
    "\n",
    "\n",
    "def target_batch_to_detections(targets, dataset, gt_field=\"ground_truth\"):\n",
    "    classes = dataset_v51.default_classes\n",
    "    batch_targets = []\n",
    "    samples = [dataset[filepath] for filepath in targets]\n",
    "    for sample in samples:\n",
    "        metadata = sample.metadata\n",
    "        id = sample.id\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        area = []\n",
    "        iscrowd = []\n",
    "        for detection in sample[gt_field][\"detections\"]:\n",
    "            category_id = classes.index(detection.label)\n",
    "            coco_obj = fouc.COCOObject.from_label(\n",
    "                detection,\n",
    "                metadata,\n",
    "                category_id=category_id,\n",
    "            )\n",
    "            x, y, w, h = coco_obj.bbox\n",
    "            boxes.append([x, y, w, h])\n",
    "            labels.append(coco_obj.category_id)\n",
    "            area.append(coco_obj.area)\n",
    "            iscrowd.append(coco_obj.iscrowd)\n",
    "\n",
    "        target_dict = {}\n",
    "        target_dict[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        target_dict[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target_dict[\"image_id\"] = id\n",
    "        target_dict[\"area\"] = torch.as_tensor(area, dtype=torch.float32)\n",
    "        target_dict[\"iscrowd\"] = torch.as_tensor(iscrowd, dtype=torch.int64)\n",
    "        batch_targets.append(target_dict)\n",
    "    return batch_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForZeroShotObjectDetection,\n",
    ")\n",
    "\n",
    "model_name = \"google/owlv2-base-patch16-ensemble\"\n",
    "texts = [\n",
    "    \"car\",\n",
    "    \"truck\",\n",
    "    \"bus\",\n",
    "    \"trailer\",\n",
    "    \"motorbike/cycler\",\n",
    "    \"pedestrian\",\n",
    "    \"van\",\n",
    "    \"pickup\",\n",
    "]\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModelForZeroShotObjectDetection.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForZeroShotObjectDetection.from_pretrained(model_name).to(device)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_classes = texts * batch_size\n",
    "tokenized_text = processor.tokenizer(\n",
    "    batch_classes, padding=\"max_length\", return_tensors=\"pt\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "Steps:  229\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(dataset_v51)\n",
    "iterations = n_samples / batch_size\n",
    "torch.cuda.empty_cache()\n",
    "steps = 0\n",
    "for batch_idx, (images, targets) in enumerate(torch_dataloader_managed):\n",
    "    print(batch_idx)\n",
    "    steps += 1\n",
    "print(\"Steps: \", steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "for batch_idx, (images, targets) in enumerate(torch_dataloader_filepaths):\n",
    "    targets = target_batch_to_detections(targets, dataset_v51)\n",
    "    target_sizes = [tuple(img.shape[1:]) for img in images]\n",
    "    inputs = processor(text=None, images=images, return_tensors=\"pt\").to(device)\n",
    "    inputs.update(tokenized_text)\n",
    "    with torch.amp.autocast(\"cuda\"):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "    results = processor.post_process_object_detection(\n",
    "        outputs=outputs,\n",
    "        threshold=0.2,\n",
    "        target_sizes=target_sizes,\n",
    "    )\n",
    "    for result, target in zip(results, targets):\n",
    "        boxes, scores, labels = result[\"boxes\"], result[\"scores\"], result[\"labels\"]\n",
    "\n",
    "        detections = []\n",
    "        for box, score, label in zip(boxes, scores, labels):\n",
    "\n",
    "            # Get image size (ID is stored in annotation)\n",
    "            sample = dataset_v51[target[\"image_id\"]]\n",
    "            img_width = sample.metadata.width\n",
    "            img_height = sample.metadata.height\n",
    "\n",
    "            # Convert bbox to V51 type\n",
    "            label = texts[label]\n",
    "            top_left_x = box[0].item() / img_width\n",
    "            top_left_y = box[1].item() / img_height\n",
    "            box_width = (box[2].item() - box[0].item()) / img_width\n",
    "            box_height = (box[3].item() - box[1].item()) / img_height\n",
    "\n",
    "            detection = fo.Detection(\n",
    "                label=label,\n",
    "                bounding_box=[\n",
    "                    top_left_x,\n",
    "                    top_left_y,\n",
    "                    box_width,\n",
    "                    box_height,\n",
    "                ],\n",
    "                confidence=score.item(),\n",
    "            )\n",
    "\n",
    "            detections.append(detection)\n",
    "\n",
    "        # Attach label to V51 dataset\n",
    "        sample = dataset_v51[target[\"image_id\"]]\n",
    "        sample[\"prediction\"] = fo.Detections(detections=detections)\n",
    "        sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "for batch_idx, (images, targets) in enumerate(torch_dataloader_managed):\n",
    "    target_sizes = [tuple(img.shape[1:]) for img in images]\n",
    "    inputs = processor(text=None, images=images, return_tensors=\"pt\").to(device)\n",
    "    inputs.update(tokenized_text)\n",
    "    with torch.amp.autocast(\"cuda\"):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "    results = processor.post_process_object_detection(\n",
    "        outputs=outputs,\n",
    "        threshold=0.2,\n",
    "        target_sizes=target_sizes,\n",
    "    )\n",
    "    for result, target in zip(results, targets):\n",
    "        boxes, scores, labels = result[\"boxes\"], result[\"scores\"], result[\"labels\"]\n",
    "\n",
    "        detections = []\n",
    "        for box, score, label, img_size in zip(boxes, scores, labels, target_sizes):\n",
    "\n",
    "            img_width = img_size[1]\n",
    "            img_height = img_size[0]\n",
    "\n",
    "            # Convert bbox to V51 type\n",
    "            label = texts[label]\n",
    "            top_left_x = box[0].item() / img_width\n",
    "            top_left_y = box[1].item() / img_height\n",
    "            box_width = (box[2].item() - box[0].item()) / img_width\n",
    "            box_height = (box[3].item() - box[1].item()) / img_height\n",
    "\n",
    "            detection = fo.Detection(\n",
    "                label=label,\n",
    "                bounding_box=[\n",
    "                    top_left_x,\n",
    "                    top_left_y,\n",
    "                    box_width,\n",
    "                    box_height,\n",
    "                ],\n",
    "                confidence=score.item(),\n",
    "            )\n",
    "\n",
    "            detections.append(detection)\n",
    "\n",
    "        # Attach label to V51 dataset\n",
    "        sample = dataset_v51[target[\"image_id\"]]\n",
    "        sample[\"prediction_managed\"] = fo.Detections(detections=detections)\n",
    "        sample.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filepaths: 10.51 with batch_size 8  \n",
    "Managed: 9.56 with batch_size 8 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
