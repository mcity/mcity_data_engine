{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates a PyTorch dataset from a FiftyOne dataset for training\n",
    "\n",
    "- https://github.com/voxel51/fiftyone-examples/blob/master/examples/pytorch_detection_training.ipynb\n",
    "- https://towardsdatascience.com/stop-wasting-time-with-pytorch-datasets-17cac2c22fa8\n",
    "- https://voxel51.com/blog/fiftyone-tips-and-tricks-for-accelerating-computer-vision-workflows-mar-17-2023/\n",
    "- https://stackoverflow.com/questions/78720028/fiftyone-dataset-with-pytorch-dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 0\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "import fiftyone as fo\n",
    "import importlib\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.data_loader\n",
    "\n",
    "importlib.reload(utils.data_loader)\n",
    "from utils.data_loader import FiftyOneTorchDatasetCOCO, TorchToHFDatasetCOCO\n",
    "\n",
    "import fiftyone as fo\n",
    "from fiftyone.utils.huggingface import load_from_hub\n",
    "\n",
    "try:\n",
    "    dataset_v51 = load_from_hub(\"dbogdollumich/mcity_fisheye_v51\")\n",
    "except:\n",
    "    dataset_v51 = fo.load_dataset(\"dbogdollumich/mcity_fisheye_v51\")\n",
    "\n",
    "torch_dataset = FiftyOneTorchDatasetCOCO(dataset_v51)\n",
    "converter_torch_hf = TorchToHFDatasetCOCO(torch_dataset)\n",
    "hf_dataset = converter_torch_hf.convert()\n",
    "\n",
    "# Access the Hugging Face dataset directly\n",
    "print(hf_dataset[\"train\"][0])\n",
    "print(hf_dataset[\"val\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import fiftyone.utils.coco as fouc\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "tokens = {}\n",
    "with open(\"/home/dbogdoll/mcity_data_engine/.secret\", \"r\") as file:\n",
    "    for line in file:\n",
    "        key, value = line.strip().split(\"=\")\n",
    "        tokens[key] = value\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = tokens[\"HF_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with Huggingface\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset_hf = load_dataset(\"dbogdollumich/mcity_fisheye_v51\", split=\"train\")\n",
    "dataset_hf[0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with Fiftyone\n",
    "import fiftyone as fo\n",
    "from fiftyone.utils.huggingface import load_from_hub\n",
    "\n",
    "try:\n",
    "    dataset_v51 = load_from_hub(\"dbogdollumich/mcity_fisheye_v51\")\n",
    "except:\n",
    "    dataset_v51 = fo.load_dataset(\"dbogdollumich/mcity_fisheye_v51\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiftyOneTorchDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A class to construct a PyTorch dataset from a FiftyOne dataset.\n",
    "\n",
    "    Args:\n",
    "        fiftyone_dataset: a FiftyOne dataset or view that will be used for training or testing\n",
    "        transforms (None): a list of PyTorch transforms to apply to images and targets when loading\n",
    "        gt_field (\"ground_truth\"): the name of the field in fiftyone_dataset that contains the\n",
    "            desired labels to load\n",
    "        classes (None): a list of class strings that are used to define the mapping between\n",
    "            class names and indices. If None, it will use all classes present in the given fiftyone_dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        fiftyone_dataset,\n",
    "        transforms=None,\n",
    "        gt_field=\"ground_truth\",\n",
    "        classes=None,\n",
    "    ):\n",
    "        self.samples = fiftyone_dataset\n",
    "        self.transforms = transforms\n",
    "        self.gt_field = gt_field\n",
    "\n",
    "        self.img_paths = self.samples.values(\"filepath\")\n",
    "\n",
    "        self.classes = classes\n",
    "        if not self.classes:\n",
    "            # Get list of distinct labels that exist in the view\n",
    "            self.classes = self.samples.distinct(\"%s.detections.label\" % gt_field)\n",
    "\n",
    "        if self.classes[0] != \"background\":\n",
    "            self.classes = [\"background\"] + self.classes\n",
    "\n",
    "        self.labels_map_rev = {c: i for i, c in enumerate(self.classes)}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        sample = self.samples[img_path]\n",
    "        metadata = sample.metadata\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        area = []\n",
    "        iscrowd = []\n",
    "        detections = sample[self.gt_field].detections\n",
    "        for det in detections:\n",
    "            category_id = self.labels_map_rev[det.label]\n",
    "            coco_obj = fouc.COCOObject.from_label(\n",
    "                det,\n",
    "                metadata,\n",
    "                category_id=category_id,\n",
    "            )\n",
    "            x, y, w, h = coco_obj.bbox\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(coco_obj.category_id)\n",
    "            area.append(coco_obj.area)\n",
    "            iscrowd.append(coco_obj.iscrowd)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target[\"image_id\"] = torch.as_tensor([idx])\n",
    "        target[\"area\"] = torch.as_tensor(area, dtype=torch.float32)\n",
    "        target[\"iscrowd\"] = torch.as_tensor(iscrowd, dtype=torch.int64)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __getitems__(self, indices):\n",
    "        samples = [self.__getitem__(idx) for idx in indices]\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def get_classes(self):\n",
    "        return self.classes\n",
    "\n",
    "    def get_splits(self):\n",
    "        splits = set()\n",
    "        for sample in self.samples.iter_samples():\n",
    "            split = sample.tags[0]  # Assuming the split is the first tag\n",
    "            splits.add(split)\n",
    "        return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset = FiftyOneTorchDataset(dataset_v51)\n",
    "print(torch_dataset)\n",
    "sample = torch_dataset[0]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch dataset to Huggingface dataset\n",
    "\n",
    "from datasets import Dataset, NamedSplit\n",
    "\n",
    "\n",
    "def gen(dataset, split_name):\n",
    "    for idx in range(len(dataset)):\n",
    "        img_path = dataset.img_paths[idx]\n",
    "        sample = dataset.samples[img_path]\n",
    "        split = sample.tags[0]\n",
    "        if split != split_name:\n",
    "            continue\n",
    "        metadata = sample.metadata\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        area = []\n",
    "        iscrowd = []\n",
    "        detections = sample[dataset.gt_field].detections\n",
    "        for det in detections:\n",
    "            category_id = dataset.labels_map_rev[det.label]\n",
    "            coco_obj = fouc.COCOObject.from_label(\n",
    "                det,\n",
    "                metadata,\n",
    "                category_id=category_id,\n",
    "            )\n",
    "            x, y, w, h = coco_obj.bbox\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(coco_obj.category_id)\n",
    "            area.append(coco_obj.area)\n",
    "            iscrowd.append(coco_obj.iscrowd)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": idx,\n",
    "            \"area\": area,\n",
    "            \"iscrowd\": iscrowd,\n",
    "        }\n",
    "\n",
    "        yield {\"image\": img_path, \"target\": target, \"split\": split}\n",
    "\n",
    "\n",
    "# Function to create HuggingFace datasets for each split\n",
    "def create_hf_dataset(torch_dataset):\n",
    "    splits = torch_dataset.get_splits()\n",
    "    hf_datasets = {}\n",
    "    for split in splits:\n",
    "        hf_datasets[split] = Dataset.from_generator(\n",
    "            lambda: gen(torch_dataset, split), split=NamedSplit(split)\n",
    "        )\n",
    "    return hf_datasets\n",
    "\n",
    "\n",
    "# Create the HuggingFace datasets\n",
    "hf_dataset = create_hf_dataset(torch_dataset)\n",
    "\n",
    "print(hf_dataset[\"train\"][0])\n",
    "print(hf_dataset[\"val\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
