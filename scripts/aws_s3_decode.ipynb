{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pytz\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import base64\n",
    "import fiftyone as fo\n",
    "import pkg_resources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set metadata for import with fiftyone\n",
    "def set_v51_metadata(output_base_dir):\n",
    "\n",
    "    # Define sample fields\n",
    "    sample_fields = [\n",
    "        {\n",
    "            \"name\": \"filepath\",\n",
    "            \"ftype\": \"fiftyone.core.fields.StringField\",\n",
    "            \"embedded_doc_type\": None,\n",
    "            \"subfield\": None,\n",
    "            \"fields\": [],\n",
    "            \"db_field\": \"filepath\",\n",
    "            \"description\": None,\n",
    "            \"info\": None,\n",
    "            \"read_only\": True,\n",
    "            \"created_at\": {\n",
    "                \"$date\": \"2024-11-14T15:24:21.719Z\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"sensor\",\n",
    "            \"ftype\": \"fiftyone.core.fields.StringField\",\n",
    "            \"embedded_doc_type\": None,\n",
    "            \"subfield\": None,\n",
    "            \"fields\": [],\n",
    "            \"db_field\": \"sensor\",\n",
    "            \"description\": None,\n",
    "            \"info\": None,\n",
    "            \"read_only\": True,\n",
    "            \"created_at\": {\n",
    "                \"$date\": \"2024-11-14T15:24:21.719Z\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"timestamp\",\n",
    "            \"ftype\": \"fiftyone.core.fields.DateTimeField\",\n",
    "            \"embedded_doc_type\": None,\n",
    "            \"subfield\": None,\n",
    "            \"fields\": [],\n",
    "            \"db_field\": \"timestamp\",\n",
    "            \"description\": None,\n",
    "            \"info\": None,\n",
    "            \"read_only\": True,\n",
    "            \"created_at\": {\n",
    "                \"$date\": \"2024-11-14T15:24:21.719Z\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Get version of current V51 package\n",
    "    package_name = 'fiftyone'\n",
    "    version = pkg_resources.get_distribution(package_name).version\n",
    "    version_str = str(version)\n",
    "\n",
    "    v51_metadata = {}\n",
    "    v51_metadata[\"name\"] = \"Data Engine Rolling Dataset\"\n",
    "    v51_metadata[\"version\"] = version_str\n",
    "    v51_metadata[\"sample_fields\"] = sample_fields\n",
    "\n",
    "    file_path = os.path.join(output_base_dir, \"metadata.json\")\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(v51_metadata, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_v51_dataset(output_base_dir, name=\"Data Engine Rolling Dataset\", delete_old_dataset=True, NUM_WORKERS=32):\n",
    "\n",
    "    # Create the dataset\n",
    "    dataset = fo.Dataset(name = name, overwrite=delete_old_dataset)\n",
    "\n",
    "    dataset.add_dir(\n",
    "        dataset_dir=output_base_dir,\n",
    "        dataset_type=fo.types.FiftyOneDataset,\n",
    "        progress=True,\n",
    "    )\n",
    "\n",
    "    dataset.compute_metadata(num_workers=NUM_WORKERS, progress=True)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_differences = []\n",
    "\n",
    "def save_base64_images(file_path, output_base_dir, v51_samples_array):\n",
    "    \n",
    "    data_target = os.path.join(output_base_dir, \"data\")\n",
    "    os.makedirs(data_target, exist_ok=True)\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in tqdm(file, desc=f\"Processing {file_path}\"):\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                v51_sample = {}\n",
    "                if \"time\" in data and \"data\" in data:\n",
    "                    # Get data\n",
    "                    timestamp = data.get(\"time\")\n",
    "                    image_base64 = data.get(\"data\")\n",
    "                    sensor_name = data.get(\"device_name\")\n",
    "\n",
    "                    # Get timestamp\n",
    "                    time_obj = datetime.datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S.%f')\n",
    "                    formatted_time = time_obj.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'\n",
    "                    \n",
    "                elif \"image\" in data and \"sensor_name\" in data and \"event_timestamp\" in data:\n",
    "                    # Get data\n",
    "                    image_base64 = data.get(\"image\")\n",
    "                    sensor_name = data.get(\"sensor_name\")\n",
    "                    timestamp = data.get(\"event_timestamp\")\n",
    "                    \n",
    "                    # Get timestamps in UTC and Michigan time\n",
    "                    utc_time = datetime.datetime.fromtimestamp(timestamp, tz=datetime.timezone.utc)\n",
    "                    michigan_tz = pytz.timezone('America/Detroit')\n",
    "                    michigan_time = utc_time.astimezone(michigan_tz)\n",
    "                    formatted_time = michigan_time.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'\n",
    "                    # TODO Make sure that the conversion to Michigan time is correct\n",
    "                else:\n",
    "                    unpacking_successful = False\n",
    "                    print(f\"Format cannot be processed: {data}\")\n",
    "                    continue\n",
    "                \n",
    "                if image_base64 and formatted_time:\n",
    "                    # Decode the base64 image data\n",
    "                    image_data = base64.b64decode(image_base64)\n",
    "\n",
    "                    # File paths\n",
    "                    image_filename = f\"{sensor_name}_{formatted_time}.jpg\"\n",
    "                    output_path = os.path.join(data_target, image_filename)\n",
    "\n",
    "                    # Ensure correct timestamp format\n",
    "                    milliseconds = formatted_time.split('.')[1][:3].ljust(3, '0')\n",
    "                    formatted_time = formatted_time.split('.')[0] + '.' + milliseconds + 'Z'\n",
    "                    iso8601_regex = re.compile(r'^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(\\.\\d{3})?Z$')\n",
    "                    iso8601_conform = bool(iso8601_regex.match(formatted_time))\n",
    "                    if not iso8601_conform:\n",
    "                        print(f\"Timestamp does not conform to ISO8601: {formatted_time}\")\n",
    "\n",
    "                    # Prepare import with V51\n",
    "                    v51_sample[\"filepath\"] = output_path\n",
    "                    v51_sample[\"sensor\"] = sensor_name\n",
    "                    v51_sample[\"timestamp\"] = {\"$date\": formatted_time}\n",
    "                    v51_samples_array.append(v51_sample) \n",
    "\n",
    "                    # Save the decoded image data as a JPEG\n",
    "                    with open(output_path, 'wb') as image_file:\n",
    "                        image_file.write(image_data)\n",
    "                else:\n",
    "                    unpacking_successful = False\n",
    "                    print(f\"There was an issue during file processing of {file}\")\n",
    "                    continue\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def calculate_time_differences(v51_samples_array):\n",
    "    timestamps = [sample[\"timestamp\"][\"$date\"] for sample in v51_samples_array]\n",
    "    timestamps.sort()\n",
    "    previous_timestamp = None\n",
    "    timestamp_format = '%Y-%m-%dT%H:%M:%S.%fZ'\n",
    "    for timestamp in timestamps:\n",
    "        if previous_timestamp is not None:\n",
    "            dt_previous_timestamp = datetime.datetime.strptime(previous_timestamp, timestamp_format)\n",
    "            dt_timestamp = datetime.datetime.strptime(timestamp, timestamp_format)\n",
    "            time_difference = dt_timestamp - dt_previous_timestamp\n",
    "            time_differences.append(time_difference.total_seconds())\n",
    "        previous_timestamp = timestamp\n",
    "\n",
    "\n",
    "data_path = \"/media/dbogdoll/Datasets/data_engine_rolling_processed/1/\"\n",
    "files = os.listdir(data_path)\n",
    "output_path = os.path.join(data_path, \"decoded_sampled\")\n",
    "\n",
    "\n",
    "v51_samples_array = []\n",
    "for file in tqdm(files, desc=\"Processing files\"):\n",
    "    if \"sip\" in file:\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        save_base64_images(file_path, output_path, v51_samples_array)\n",
    "\n",
    "# Store V51 metadata files\n",
    "v51_samples = {\"samples\": v51_samples_array}\n",
    "file_path = os.path.join(output_path, \"samples.json\")\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(v51_samples, json_file)\n",
    "\n",
    "set_v51_metadata(output_path)\n",
    "\n",
    "calculate_time_differences(v51_samples_array)\n",
    "\n",
    "print(f\"Processed {len(v51_samples_array)} images\")\n",
    "\n",
    "create_v51_dataset(output_base_dir=output_path, name=\"AWS Test Sampled (38)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(len(time_differences))\n",
    "plt.scatter(x, time_differences)\n",
    "\n",
    "# Calculate average and median\n",
    "average_time_diff = np.mean(time_differences)\n",
    "median_time_diff = np.median(time_differences)\n",
    "\n",
    "plt.axhline(y=average_time_diff, color='r', linestyle='-', label=f'Average: {average_time_diff:.2f} seconds')\n",
    "plt.axhline(y=median_time_diff, color='g', linestyle='--', label=f'Median: {median_time_diff:.2f} seconds')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Time Difference (s)')\n",
    "plt.title('Time Differences Between Consecutive Timestamps')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
