{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "### To get a first feel of the Mcity Data Engine, we provide an online demo in a Google Colab environment. \n",
    "#### We will load the Fisheye8K dataset and demonstrate the Mcity Data Engine workflow Embedding Selection. This workflow leverages a set of models to compute image embeddings. After Voxel51 app is launched, the user can explore images using embedding space to identify the dataset for training data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Mcity data engine in Google Colab.\n",
    "\n",
    "## You have 2 options to choose:\n",
    "\n",
    "### <b>Option 1</b> Run commands step by step\n",
    "\n",
    "#### Go to <b>2.Step-by-Step Intructions </b> below\n",
    "\n",
    "### <b>Option 2</b> Run All\n",
    "\n",
    "#### Go to Header Menu-> Click on Runtime and select Run All (as per the below image) for the outcome:\n",
    "\n",
    "\n",
    "<b> Chrome's Appearance Mode is Dark </b>\n",
    "\n",
    "![image](https://github.com/user-attachments/assets/3ff8c429-6644-4f40-8cd2-3f570eeed089)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 2. Step-by-Step Instructions\n",
    "\n",
    "## ⚠️ Cell output is disabled by default. To print cell output, remove the <b>%%capture</b> and rerun ⚠️\n",
    "\n",
    "### <b>Step 1</b>: Clone the mcity_data_engine GitHub repository using below command. This command will remove the existing folder (if any) and clone it from GitHub. This will make a copy of the code in the current Google Colab session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcmjORRe-ERh"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!rm -rf mcity_data_engine && git clone https://github.com/mcity/mcity_data_engine.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Step 2</b>: Copy the local copy of the code [from Step 1] to workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21GvhLMh-O_L"
   },
   "outputs": [],
   "source": [
    "!cp -R mcity_data_engine/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Step 3</b>: To execute embedding workflow, some configuration changes required. Same will be done by below script for Colab workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install typed-ast\n",
    "!python update_config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Step 4</b>: Install Colab specific data engine requirements for this exercise.\n",
    "#### <b>⚠️ It will take 5-6 minutes to install requirements ⚠️</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43WVSrfh-TzX"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements_colab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Step 5</b>: Configure Huggingface timeout variables to avoid session timeouts due to default timeout values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-IDicEF_yqn"
   },
   "outputs": [],
   "source": [
    "!export HF_HUB_ETAG_TIMEOUT=5000\n",
    "!export HF_HUB_DOWNLOAD_TIMEOUT=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Step 6</b>: This exercise uses an open-source dataset named Voxel51/fisheye8k available on Hggingface,  which will be downloaded in this step. The Max_samples parameter is set to 100 (images from the dataset) for fast processing, but it can be increased to 8000 if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from fiftyone.utils.huggingface import load_from_hub\n",
    "import fiftyone as fo\n",
    "\n",
    "if fo.dataset_exists(\"fisheye8k\"):\n",
    "  fo.delete_dataset(\"fisheye8k\")\n",
    "\n",
    "dataset = load_from_hub(\n",
    "    \"Voxel51/fisheye8k\",\n",
    "    name = \"fisheye8k\",\n",
    "    max_samples=100,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Step 7</b>: Start embedding workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Step 8</b>: Set up the Voxel51 app layout for the dataset for which embeddings are computed. After Voxel51 app is launched, the user can explore images using embedding space to identify the dataset for training data. \n",
    "\n",
    "   ### Below are the key fields related to embedding, which you will find on the left filter once the Voxel51 app is opened:\n",
    "\n",
    "- <b> embedding_selection --> </b> Type of selection (stages of the internal selection process)\n",
    "\n",
    "- <b> embedding_selection_model --> </b> Which embedding model was responsible for the first selection\n",
    "\n",
    "- <b> embedding_selection_count --> </b> How often it was selected\n",
    "\n",
    "  ![image](https://github.com/user-attachments/assets/3c8c46d8-0545-4dc5-aa7c-09f319aca450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSfyF4bzH5bX"
   },
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "samples_panel = fo.Panel(type=\"Samples\", pinned=True)\n",
    "\n",
    "embeddings_panel = fo.Panel(\n",
    "    type=\"Embeddings\",\n",
    "    state=dict(brainResult=\"clip_vit_base32_torch_umap\", colorByField=\"embedding_selection_count\"),\n",
    ")\n",
    "\n",
    "spaces = fo.Space(\n",
    "    children=[\n",
    "                fo.Space(children=[samples_panel], active_child=samples_panel.component_id),\n",
    "                fo.Space(children=[embeddings_panel], active_child=embeddings_panel.component_id),\n",
    "            ],\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "\n",
    "session =fo.launch_app(dataset=dataset,spaces=spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Handling Errors and Troubleshooting\n",
    "* The Voxel51 app may take 1-2 minutes to launch, depending on your internet speed.\n",
    "* If no images appear in the Samples Panel or Embeddings Panel, manually click on the Samples or Embeddings tab to load them (refer Voxel51 [Tutorial](https://docs.voxel51.com/tutorials/image_embeddings.html)).\n",
    "\n",
    "# 4. Additional Notes and Best Practices\n",
    "* Always ensure your runtime is set to GPU for optimal performance.\n",
    "* Keep an eye on execution logs for warnings or errors.\n",
    "* Save your work frequently to avoid losing progress.\n",
    "\n",
    "\n",
    "By following this manual, you will be able to execute the Fish Eye 8K notebook in Google Colab efficiently. Happy coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
