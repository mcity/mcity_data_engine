{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "To get a first feel of the Mcity Data Engine, we provide an online demo in a Google Colab environment. We will load the Fisheye8K dataset and demonstrate the Mcity Data Engine workflow Embedding Selection. This workflow leverage a set of models to compute image embeddings. This subset will finally be visualized in the Voxel51 UI, highlighting how often a sample was picked by a model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go to Header -> Click on Runtime and select Run All (as per the below image) for the outcome or follow the steps below:\n",
    "\n",
    "\n",
    "<b> Chrome's Appearance Mode is Dark </b>\n",
    "\n",
    "![image](https://github.com/user-attachments/assets/68a5fecd-41ac-42b9-83f9-8c52b8cd96e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 2. Step-by-Step Instructions\n",
    "\n",
    "### <b>Step 1</b>: Clone the mcity_data_engine GitHub repository using bewlow command. This command will remove the existing folder (if any) and clone it from GitHub. This will make a copy of the code in the current Google Colab session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcmjORRe-ERh"
   },
   "outputs": [],
   "source": [
    "!rm -rf mcity_data_engine && git clone https://github.com/mcity/mcity_data_engine.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Step 2</b>: Copy the local copy of the code [from Step 1] to workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21GvhLMh-O_L"
   },
   "outputs": [],
   "source": [
    "!cp -R mcity_data_engine/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Step 3</b>: To execute embedding WORKFLOW, some configuration changes required. Same will be done by below script for Colab workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install typed-ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import _ast\n",
    "\n",
    "\n",
    "config_file_path = './config/config.py'\n",
    "\n",
    "UPDATED_WORKFLOWS =    { \"embedding_selection\": {\n",
    "        \"mode\": \"compute\",\n",
    "        \"parameters\": {\n",
    "            \"compute_representativeness\": 0.99,\n",
    "            \"compute_unique_images_greedy\": 0.01,\n",
    "            \"compute_unique_images_deterministic\": 0.99,\n",
    "            \"compute_similar_images\": 0.03,\n",
    "            \"neighbour_count\": 3,\n",
    "        },\n",
    "        \"embedding_models\": [\n",
    "            \"detection-transformer-torch\",\n",
    "            \"zero-shot-detection-transformer-torch\",\n",
    "            \"clip-vit-base32-torch\",\n",
    "        ],\n",
    "    },}\n",
    "\n",
    "class ConfigVisitor(ast.NodeTransformer):\n",
    "        def visit_Assign(self, node):\n",
    "            # Look for the assignment of the variables we want to modify\n",
    "            if isinstance(node.targets[0], _ast.Name):\n",
    "                if node.targets[0].id == \"SELECTED_WORKFLOW\":\n",
    "                    node.value = ast.Constant(value=[\"embedding_selection\"] )\n",
    "                elif node.targets[0].id == \"WORKFLOWS\":\n",
    "                    node.value = ast.Constant(value=UPDATED_WORKFLOWS)\n",
    "                elif node.targets[0].id == \"WANDB_ACTIVE\":\n",
    "                    node.value = ast.Constant(value=False)\n",
    "                elif node.targets[0].id == \"V51_REMOTE\":\n",
    "                    node.value = ast.Constant(value=False)                                      \n",
    "            return node\n",
    "\n",
    "    # Transform the AST\n",
    "transformer = ConfigVisitor()\n",
    "\n",
    "with open(config_file_path, \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "parsed_ast = ast.parse(content)\n",
    "updated_ast = transformer.visit(parsed_ast)\n",
    "\n",
    "    # Convert AST back to source code\n",
    "    \n",
    "updated_content = ast.unparse(updated_ast)\n",
    "\n",
    "with open(config_file_path, \"w\") as file:\n",
    "    file.write(updated_content)\n",
    "\n",
    "print(\"Config file updated successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Step 4</b>: Install Colab specific data engine requirements for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43WVSrfh-TzX"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements_colab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Step 5</b>: Configure Huggingface timeout variables to avoid session timeouts due to default timeout values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-IDicEF_yqn"
   },
   "outputs": [],
   "source": [
    "!export HF_HUB_ETAG_TIMEOUT=5000\n",
    "!export HF_HUB_DOWNLOAD_TIMEOUT=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Step 6</b>: This exercise uses an opensource dataset named Voxel51/fisheye8k available on Hggingface,Â  which will be downloaded in this step. The Max_samples parameter is set to 100 for fast processing, but it can be increased to 8000 if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone.utils.huggingface import load_from_hub\n",
    "import fiftyone as fo\n",
    "\n",
    "if fo.dataset_exists(\"fisheye8k\"):\n",
    "  fo.delete_dataset(\"fisheye8k\")\n",
    "\n",
    "dataset = load_from_hub(\n",
    "    \"Voxel51/fisheye8k\",\n",
    "    name = \"fisheye8k\",\n",
    "    max_samples=100,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Step 7</b>: Start embedding WORKFLOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Step 8</b>: Set up the Voxel51 app layout for the dataset for which embeddings are computed\n",
    "\n",
    "   ### Below are the key fields related to embedding, which you will find on the left filter once the Voxel51 app is opened:\n",
    "\n",
    "- <b> embedding_selection --> </b> Type of selection (stages of the internal selection process)\n",
    "\n",
    "- <b> embedding_selection_model --> </b> Which embedding model was responsible for the first selection\n",
    "\n",
    "- <b> embedding_selection_count --> </b> How often it was selected\n",
    "\n",
    "  ![image](https://github.com/user-attachments/assets/3c8c46d8-0545-4dc5-aa7c-09f319aca450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSfyF4bzH5bX"
   },
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "samples_panel = fo.Panel(type=\"Samples\", pinned=True)\n",
    "\n",
    "embeddings_panel = fo.Panel(\n",
    "    type=\"Embeddings\",\n",
    "    state=dict(brainResult=\"clip_vit_base32_torch_umap\", colorByField=\"embedding_selection_count\"),\n",
    ")\n",
    "\n",
    "spaces = fo.Space(\n",
    "    children=[\n",
    "                fo.Space(children=[samples_panel]),\n",
    "                fo.Space(children=[embeddings_panel]),\n",
    "            ],\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "fo.launch_app(dataset=fo.load_dataset('fisheye8k'),spaces=spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Handling Errors and Troubleshooting\n",
    "* The Voxel51 app may take 1-2 minutes to launch, depending on your internet speed.\n",
    "* If no images appear in the Samples Panel or Embeddings Panel, manually click on the Samples or Embeddings tab to load them (refer Voxel51 [Tutorial](https://docs.voxel51.com/tutorials/image_embeddings.html)).\n",
    "\n",
    "# 4. Additional Notes and Best Practices\n",
    "* Always ensure your runtime is set to GPU for optimal performance.\n",
    "* Keep an eye on execution logs for warnings or errors.\n",
    "* Save your work frequently to avoid losing progress.\n",
    "\n",
    "\n",
    "By following this manual, you will be able to execute the Fish Eye 8K notebook in Google Colab efficiently. Happy coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
